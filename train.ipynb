{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from ops import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers.convolutional import Convolution2D, Deconvolution2D\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.core import Activation, Lambda\n",
    "from keras.layers import Input, merge\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "import h5py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "color_image_path = r\"C:\\Users\\Promise\\Desktop\\AI Projects\\Sketchback\\dataset\\training\\resized\\a\\f-005-01.png\"\n",
    "sketch_image_path = r\"C:\\Users\\Promise\\Desktop\\AI Projects\\Sketchback\\dataset\\training\\resized\\b\\f-005-01.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img = mpimg.imread(color_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(256, 256, 3)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1b879c0a550>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sketch = mpimg.imread(sketch_image_path)\n",
    "print (sketch.shape)\n",
    "plt.imshow(sketch[:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import vgg16\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Promise\\Miniconda2\\envs\\ztdl\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"bl..., inputs=Tensor(\"in...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "base_model = vgg16.VGG16(weights='imagenet', include_top=False)\n",
    "vgg = Model(input=base_model.input, output=base_model.get_layer('block2_conv2').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_vgg(x, data_format=None):\n",
    "    if data_format is None:\n",
    "        data_format = K.image_data_format()\n",
    "    assert data_format in {'channels_last', 'channels_first'}\n",
    "    x = 255. * x\n",
    "    if data_format == 'channels_first':\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, ::-1, :, :]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, 0, :, :] = x[:, 0, :, :] - 103.939\n",
    "        x[:, 1, :, :] = x[:, 1, :, :] - 116.779\n",
    "        x[:, 2, :, :] = x[:, 2, :, :] - 123.68\n",
    "    else:\n",
    "        # 'RGB'->'BGR'\n",
    "        x = x[:, :, :, ::-1]\n",
    "        # Zero-center by mean pixel\n",
    "        x[:, :, :, 0] = x[:, :, :, 0] - 103.939\n",
    "        x[:, :, :, 1] = x[:, :, :, 1] - 116.779\n",
    "        x[:, :, :, 2] = x[:, :, :, 2] - 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(Y):\n",
    "    Z = deepcopy(Y)\n",
    "    Z = preprocess_vgg(Z)\n",
    "    features = vgg.predict(Z, batch_size = 5, verbose = 0)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = get_features(img.reshape(-1,256,256,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature = feature.reshape(256,256,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m = 256\n",
    "n = 256\n",
    "image_path = r\"C:\\Users\\Promise\\Desktop\\AI Projects\\Sketchback\\dataset\\training\\resized\\a\"\n",
    "sketch_path = r\"C:\\Users\\Promise\\Desktop\\AI Projects\\Sketchback\\dataset\\training\\resized\\b\"\n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_file_names(path):\n",
    "    return os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(X = True, Y = True, W = True):\n",
    "    \n",
    "    x_path = sketch_path\n",
    "    y_path = image_path\n",
    "    file_names = load_file_names(x_path)\n",
    "\n",
    "    X_train = np.zeros((len(file_names), m, n), dtype='float32')\n",
    "    Y_train = np.zeros((len(file_names), m, n, 3), dtype='float32')\n",
    "    F_train = None\n",
    "\n",
    "    \n",
    "    \n",
    "        \n",
    "    if X:\n",
    "        # Load Sketches\n",
    "        for i in range(len(file_names)):\n",
    "            file = os.path.join(x_path, file_names[i])\n",
    "            img = mpimg.imread(file)\n",
    "            img = img.astype('float32')\n",
    "            try:\n",
    "                X_train[i] = img[:,:,0] / 255.\n",
    "            except:\n",
    "                X_train[i] = img[:,:] / 255\n",
    "            \n",
    "    if Y:\n",
    "        # Load Ground-truth Images\n",
    "        for i in range(len(file_names)):\n",
    "            file = os.path.join(y_path, file_names[i])\n",
    "            img = mpimg.imread(file)\n",
    "            img = img.astype('float32')\n",
    "            Y_train[i] = img / 255.\n",
    "    \n",
    "    if W:\n",
    "        F_train = get_features(Y_train)\n",
    "    \n",
    "    X_train = np.reshape(X_train, (len(file_names), m, n, 1))\n",
    "    return X_train, Y_train, F_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.utils import generic_utils\n",
    "from ops import *\n",
    "import keras.backend as K\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import sys\n",
    "# Utils\n",
    "sys.path.append(\"utils/\")\n",
    "from simple_utils import plot_batch_train, plot_batch_eval\n",
    "\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def feature_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "\n",
    "def pixel_loss(y_true, y_pred):\n",
    "    return K.sqrt(K.mean(K.square(y_true - y_pred)))\n",
    "\n",
    "\n",
    "def variation_loss(y_true, y_pred):\n",
    "    # Assume img size is 64*64\n",
    "    if K.image_dim_ordering() == 'tf':\n",
    "        a = K.square(y_pred[:, :64-1, :64-1, :] - y_pred[:, 1:, :64-1, :])\n",
    "        b = K.square(y_pred[:, :64-1, :64-1, :] - y_pred[:, :64-1, 1:, :])\n",
    "    else:\n",
    "        a = K.square(y_pred[:, :, 64 - 1, :64 - 1] - y_pred[:, :, 1:, :64 - 1])\n",
    "        b = K.square(y_pred[:, :, 64 - 1, :64 - 1] - y_pred[:, :, :64 - 1, 1:])\n",
    "    return K.sum(K.sqrt(a+b))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(batch_size, n_batch_per_epoch, nb_epoch, sketch, color, weights, save_weight=1, img_dim=[256,256,1]):\n",
    "    opt = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-8)\n",
    "    model, model_name = edge2color(img_dim, batch_size=batch_size)\n",
    "\n",
    "    model.compile(loss=[pixel_loss, feature_loss], loss_weights=[1, 1], optimizer=opt)\n",
    "    model.summary()\n",
    "#     plot_model(model, to_file='figures/edge2color.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    global_counter = 1\n",
    "    for epoch in range(nb_epoch):\n",
    "        batch_counter = 1\n",
    "        start = time.time()\n",
    "        batch_idxs = sketch.shape[0] // batch_size\n",
    "        if n_batch_per_epoch >= batch_idxs or n_batch_per_epoch == 0:\n",
    "            n_batch_per_epoch = batch_idxs\n",
    "        progbar = generic_utils.Progbar(n_batch_per_epoch * batch_size)\n",
    "\n",
    "        sk_val = sketch[0:16]\n",
    "        co_val = color[0:16]\n",
    "        sketch = sketch[16:]\n",
    "        color = color[16:]\n",
    "        weights = weights[16:]\n",
    "\n",
    "        for idx in range(batch_idxs):\n",
    "            batch_sk = sketch[idx * batch_size: (idx + 1) * batch_size]\n",
    "            batch_co = color[idx * batch_size: (idx + 1) * batch_size]\n",
    "            batch_weights = weights[idx * batch_size: (idx + 1) * batch_size]\n",
    "            train_loss = model.train_on_batch([batch_sk], [batch_co, batch_weights])\n",
    "            batch_counter += 1\n",
    "            progbar.add(batch_size, values=[('pixel_loss', train_loss[1]), ('feature_loss', train_loss[2])])\n",
    "            # if batch_counter >= n_batch_per_epoch:\n",
    "            if global_counter % 50 == 1:\n",
    "               \n",
    "                global_counter = global_counter + 1\n",
    "\n",
    "            if batch_counter >= n_batch_per_epoch:\n",
    "                break\n",
    "        print (\"\")\n",
    "        print ('Epoch %s/%s, Time: %s' % (epoch + 1, nb_epoch, time.time() - start))\n",
    "\n",
    "        if save_weight:\n",
    "            # save weights every epoch\n",
    "            weights_path = '%s/%s_weights_epoch_%s.h5' % (model_name, tag, epoch)\n",
    "            if not os.path.exists('%s' % model_name):\n",
    "                os.mkdir('%s' % model_name)\n",
    "            model.save_weights(weights_path, overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, n_batch_per_epoch, nb_epoch = 30, 10, 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketches, colors, features = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (9, 9), name=\"block1_conv2D\", padding=\"same\", strides=(1, 1))`\n",
      "  x = Convolution2D(nb_filter, k_size, k_size, name=name, border_mode=\"same\", subsample=subsample)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(64, (3, 3), name=\"block2_conv2D\", padding=\"same\", strides=(2, 2))`\n",
      "  x = Convolution2D(nb_filter, k_size, k_size, name=name, border_mode=\"same\", subsample=subsample)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:77: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block3_conv2D\", padding=\"same\", strides=(2, 2))`\n",
      "  x = Convolution2D(nb_filter, k_size, k_size, name=name, border_mode=\"same\", subsample=subsample)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block4_conv2Da\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block4_conv2Db\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(r)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:70: UserWarning: The `merge` function is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  x = merge([x, r], mode='sum', concat_axis=1, name=\"block%s_merge\" % block_idx)\n",
      "C:\\Users\\Promise\\Miniconda2\\envs\\ztdl\\lib\\site-packages\\keras\\legacy\\layers.py:456: UserWarning: The `Merge` layer is deprecated and will be removed after 08/2017. Use instead layers from `keras.layers.merge`, e.g. `add`, `concatenate`, etc.\n",
      "  name=name)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block5_conv2Da\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block5_conv2Db\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(r)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block6_conv2Da\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block6_conv2Db\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(r)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block7_conv2Da\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block7_conv2Db\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(r)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:56: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block8_conv2Da\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:64: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(128, (3, 3), name=\"block8_conv2Db\", padding=\"same\", kernel_regularizer=<keras.reg...)`\n",
      "  r = Convolution2D(nb_filter, k_size, k_size, border_mode=\"same\", W_regularizer=W_reg, name=name)(r)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:101: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(64, (3, 3), name=\"block9_deconv2D\", padding=\"same\", strides=(2, 2))`\n",
      "  x = Deconvolution2D(nb_filter, k_size, k_size, output_shape=output_shape, name=name, border_mode='same', subsample=subsample)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:101: UserWarning: Update your `Conv2DTranspose` call to the Keras 2 API: `Conv2DTranspose(32, (3, 3), name=\"block10_deconv2D\", padding=\"same\", strides=(2, 2))`\n",
      "  x = Deconvolution2D(nb_filter, k_size, k_size, output_shape=output_shape, name=name, border_mode='same', subsample=subsample)(x)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:90: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(3, (9, 9), name=\"block11_conv2D\", padding=\"same\", strides=(1, 1))`\n",
      "  x = Convolution2D(nb_filter, k_size, k_size, name=name, border_mode=\"same\", subsample=subsample)(x)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 256, 256, 1)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv2D (Conv2D)       (None, 256, 256, 32)      2624      \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 256, 256, 32)      1024      \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv2D (Conv2D)       (None, 128, 128, 64)      18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 128, 128, 64)      512       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block3_conv2D (Conv2D)       (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv2Da (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block4_bna (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block4_relua (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv2Db (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block4_bnb (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block4_relub (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block4_merge (Merge)         (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv2Da (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block5_bna (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block5_relua (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv2Db (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block5_bnb (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block5_relub (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block5_merge (Merge)         (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block6_conv2Da (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block6_bna (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block6_relua (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block6_conv2Db (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block6_bnb (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block6_relub (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block6_merge (Merge)         (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block7_conv2Da (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block7_bna (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block7_relua (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block7_conv2Db (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block7_bnb (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block7_relub (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block7_merge (Merge)         (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block8_conv2Da (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block8_bna (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block8_relua (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block8_conv2Db (Conv2D)      (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block8_bnb (BatchNormalizati (None, 64, 64, 128)       256       \n",
      "_________________________________________________________________\n",
      "block8_relub (Activation)    (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block8_merge (Merge)         (None, 64, 64, 128)       0         \n",
      "_________________________________________________________________\n",
      "block9_deconv2D (Conv2DTrans (None, 128, 128, 64)      73792     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 128, 128, 64)      512       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 128, 128, 64)      0         \n",
      "_________________________________________________________________\n",
      "block10_deconv2D (Conv2DTran (None, 256, 256, 32)      18464     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 256, 256, 32)      1024      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 256, 256, 32)      0         \n",
      "_________________________________________________________________\n",
      "block11_conv2D (Conv2D)      (None, 256, 256, 3)       7779      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 256, 256, 3)       1024      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "lambda_2 (Lambda)            (None, 256, 256, 3)       0         \n",
      "_________________________________________________________________\n",
      "model_3 (Model)              multiple                  260160    \n",
      "=================================================================\n",
      "Total params: 1,937,923.0\n",
      "Trainable params: 1,674,307.0\n",
      "Non-trainable params: 263,616.0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:152: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=Tensor(\"bl..., inputs=Tensor(\"in...)`\n",
      "  vgg_first2 = Model(input=vgg_16.input, output=vgg_16.get_layer('block2_conv2').output)\n",
      "C:\\Users\\Promise\\Desktop\\AI Projects\\Convolutional_Sketch_Inversion\\src\\ops.py:158: UserWarning: Update your `Model` call to the Keras 2 API: `Model(name=\"edge2color\", outputs=[<tf.Tenso..., inputs=Tensor(\"in...)`\n",
      "  model = Model(input=x_input, output=[h11, feat], name='edge2color')\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'pydot' has no attribute 'find_graphviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b04f50dbc1f7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_batch_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msketches\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-28-89fc40e3592b>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(batch_size, n_batch_per_epoch, nb_epoch, sketch, color, weights, save_weight, img_dim)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpixel_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeature_loss\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'figures/edge2color.png'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mglobal_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda2\\envs\\ztdl\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[1;34m(model, to_file, show_shapes, show_layer_names)\u001b[0m\n\u001b[0;32m     98\u001b[0m                \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m                show_layer_names=True):\n\u001b[1;32m--> 100\u001b[1;33m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    101\u001b[0m     \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda2\\envs\\ztdl\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[1;34m(model, show_shapes, show_layer_names)\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m     \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m     \u001b[0mdot\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mdot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rankdir'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'TB'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Miniconda2\\envs\\ztdl\\lib\\site-packages\\keras\\utils\\vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_check_pydot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpydot\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0;32m     18\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pydot' has no attribute 'find_graphviz'"
     ]
    }
   ],
   "source": [
    "train(batch_size, n_batch_per_epoch, nb_epoch, sketches, colors, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
